# DeepFake-Detector: Система распознавания лиц с защитой от DeepFake

Проект предназначен для обучения модели распознавания лиц, способной отличать реальные лица от синтетических, созданных с помощью технологии DeepFake. Система использует метрическое обучение и оптимизирована для задач верификации, где:

1. Косинусное сходство (cosine similarity) эмбеддингов двух изображений должно быть высоким для фотографий одного реального человека.
2. Косинусное сходство должно быть низким для фотографий разных людей или для пары "реальное фото - DeepFake".

## Содержание

- [Структура проекта](#структура-проекта)
- [Требования](#требования)
- [Установка](#установка)
- [Использование](#использование)
  - [Обучение модели](#обучение-модели)
  - [Конфигурация](#конфигурация)
  - [Структура эксперимента](#структура-эксперимента)
- [Компоненты системы](#компоненты-системы)
  - [Модели](#модели)
  - [Функции потерь и майнеры](#функции-потерь-и-майнеры)
  - [Сэмплеры](#сэмплеры)
  - [Метрики](#метрики)
- [Процесс валидации](#процесс-валидации)
- [Логирование](#логирование)
- [Управление чекпоинтами](#управление-чекпоинтами)

## Структура проекта

```
deepfake_detector/
├── config/               # Модуль для работы с конфигурацией
│   └── config_utils.py   # Утилиты для загрузки и сохранения конфигурации
├── data/                 # Модуль для работы с данными
│   └── data_utils.py     # Утилиты для создания датасетов и загрузчиков данных
├── metrics/              # Метрики для оценки качества модели
│   └── metrics.py        # Реализация метрик (EER, MAP@K, CMC@K)
├── models/               # Модуль для работы с моделями
│   └── model_utils.py    # Утилиты для инициализации моделей и компонентов
├── trainer/              # Модуль для обучения модели
│   └── trainer.py        # Класс Trainer, управляющий процессом обучения
├── utils/                # Вспомогательные утилиты
│   ├── checkpoint_utils.py   # Работа с чекпоинтами моделей
│   ├── experiment_utils.py   # Управление экспериментами
│   └── logging_utils.py      # Логирование и TensorBoard
├── validation/           # Модуль для валидации модели
│   └── validator.py      # Функции для валидации и расчета метрик
├── configs/              # Директория с конфигурационными файлами
│   └── config.yaml       # Пример конфигурации
└── train.py              # Основной скрипт запуска обучения
```

## Требования

- Python 3.8+
- PyTorch 1.10+
- open-metric-learning
- pandas
- numpy
- scikit-learn
- tqdm
- PyYAML

## Установка

1. Клонируйте репозиторий:
   ```bash
   git clone https://github.com/your_username/deepfake-detector.git
   cd deepfake-detector
   ```

2. Установите зависимости:
   ```bash
   pip install -r requirements.txt
   ```

## Использование

### Обучение модели

Базовый запуск с конфигурацией по умолчанию:

```bash
python train.py
```

С указанием пути к конфигурации:

```bash
python train.py --config configs/config.yaml
```

Продолжение обучения с чекпоинта:

```bash
python train.py --checkpoint path/to/checkpoint.pth
```

Установка конкретного seed для воспроизводимости:

```bash
python train.py --seed 42
```

### Конфигурация

Все параметры обучения настраиваются в файле `config.yaml`. Ниже приведены основные разделы и их описание:

#### Пути к данным
```yaml
data:
  train_path: "path/to/train.csv"  # Путь к CSV с обучающими данными
  val_path: "path/to/val.csv"      # Путь к CSV с валидационными данными
```

CSV файлы должны содержать следующие колонки:
- `label` - идентификатор лица/персоны
- `path` - путь к изображению
- `split` - разделение (train, validation)
- `is_query` - флаг для поисковых запросов (True/False)
- `is_gallery` - флаг для галереи (True/False)
- `category` - категория (real/fake)

#### Настройки модели
```yaml
model:
  name: "vits14_reg_dinov2"  # Название архитектуры
  save_dir: "models/"        # Директория для сохранения моделей
```

#### Параметры обучения
```yaml
training:
  epochs: 8               # Количество эпох
  batch_size: 32          # Размер батча
  seed: 0                 # Seed для воспроизводимости
  device: "cuda:0"        # Устройство (cuda:0, cuda:1, cpu)
  validate_every: 1       # Проводить валидацию каждые N эпох
  num_workers: 4          # Количество workers для DataLoader
```

#### Настройки оптимизатора
```yaml
optimizer:
  name: "Adam"            # Тип оптимизатора (Adam, AdamW)
  lr: 1e-4                # Скорость обучения
  weight_decay: 0.0001    # Коэффициент L2-регуляризации (для AdamW)
```

#### Настройки планировщика скорости обучения
```yaml
scheduler:
  name: "CosineAnnealingWarmRestarts"  # Тип планировщика
  T_0: 5                  # Период первого перезапуска (для CosineAnnealingWarmRestarts)
  T_mult: 2               # Множитель периодов (для CosineAnnealingWarmRestarts)
  eta_min: 1e-6           # Минимальное значение lr
```

#### Настройки функции потерь и майнера
```yaml
loss:
  name: "TripletLoss"     # Тип функции потерь (TripletLoss, ArcFaceLoss)
  margin: 0.3             # Margin для TripletLoss
```

```yaml
miner:
  name: "AllTripletsMiner"  # Тип майнера триплетов (AllTripletsMiner, HardTripletsMiner)
```

#### Настройки сэмплера
```yaml
sampler:
  name: "CategoryBalanceSampler"  # Тип сэмплера
  n_labels: 8                     # Количество меток в батче
  n_instances: 6                  # Количество экземпляров каждой метки
  n_categories: 2                 # Количество категорий (для CategoryBalanceSampler)
```

#### Настройки валидации
```yaml
validation:
  batch_size: 32          # Размер батча для валидации
  num_workers: 4          # Количество workers для валидации
  n_std: 2                # Стандартные отклонения для AdaptiveThresholding
```

#### Настройки логирования и экспериментов
```yaml
experiment:
  save_dir: "experiments/"  # Директория для сохранения результатов
  save_results: true        # Сохранять результаты в CSV
  tensorboard: true         # Использовать TensorBoard
  save_best_only: true      # Сохранять только лучшую модель
  metric_for_best: "eer"    # Метрика для отслеживания (eer или loss)
  save_every: 5             # Сохранять модель каждые N эпох
```

### Структура эксперимента

При каждом запуске обучения создаётся новая директория эксперимента в формате:
```
experiments/<hash>_<timestamp>/
```

Эта директория содержит:
- `config.yaml` - Копия конфигурации эксперимента
- `logs/` - Директория с логами обучения
  - `training.log` - Лог процесса обучения
- `tensorboard/` - Директория с логами TensorBoard
- `models/` - Директория с сохранёнными моделями
  - `best_model.pth` - Чекпоинт лучшей модели с состоянием оптимизатора и планировщика
  - `best_weights.pth` - Веса лучшей модели
  - `final_model.pth` - Веса финальной модели после последней эпохи
- `results.csv` - Таблица с результатами по эпохам

## Компоненты системы

### Модели

Проект использует модели из библиотеки `open-metric-learning`, основанные на архитектуре Vision Transformer (ViT). Доступные модели:

- `vits16_dino` - ViT Small с патчами 16x16, предобученная на DINO
- `vitb16_dino` - ViT Base с патчами 16x16, предобученная на DINO
- `vits14_dinov2` - ViT Small с патчами 14x14, предобученная на DINOv2
- `vits14_reg_dinov2` - Регистровая версия ViT Small, предобученная на DINOv2
- `vitb14_reg_dinov2` - Регистровая версия ViT Base, предобученная на DINOv2
- `vitl14_reg_dinov2` - Регистровая версия ViT Large, предобученная на DINOv2

### Функции потерь и майнеры

Для обучения используются следующие функции потерь:

- **TripletLoss**: Классическая функция потерь для метрического обучения, которая минимизирует расстояние между якорем и положительным примером, и максимизирует расстояние между якорем и отрицательным примером.
  - Параметр `margin` устанавливает минимальное желаемое расстояние между положительными и отрицательными парами.

- **ArcFaceLoss**: Улучшенная версия SoftmaxLoss с добавлением углового margin, улучшающая разделение классов.
  - Параметр `scale` контролирует масштаб логитов.
  - Параметр `margin_arcface` устанавливает угловое расстояние между классами.

Майнеры определяют стратегию выбора триплетов для обучения:

- **AllTripletsMiner**: Создаёт все возможные триплеты в батче.
- **HardTripletsMiner**: Создаёт только "сложные" триплеты, где отрицательные примеры близки к положительным.

### Сэмплеры

Сэмплеры управляют формированием батчей для обучения:

- **BalanceSampler**: Обеспечивает баланс классов в батче. Параметры:
  - `n_labels` - количество различных классов в батче.
  - `n_instances` - количество примеров каждого класса.

- **CategoryBalanceSampler**: Расширение BalanceSampler, которое дополнительно учитывает категории (real/fake). Параметры:
  - Те же, что у BalanceSampler
  - `n_categories` - количество категорий в батче (real/fake).

### Метрики

Для оценки качества модели используются следующие метрики:

- **EER (Equal Error Rate)**: Точка, в которой FAR (False Accept Rate) равен FRR (False Reject Rate). Чем ниже EER, тем лучше модель в задаче верификации.

- **MAP@K (Mean Average Precision)**: Средняя точность для топ-K результатов поиска. Показывает, насколько хорошо модель ранжирует правильные результаты в топе выдачи.

- **CMC@K (Cumulative Matching Characteristic)**: Вероятность того, что правильный результат находится в топ-K выдачи. CMC@1 соответствует точности в топ-1.

## Процесс валидации

Валидация модели включает несколько этапов:

1. Получение эмбеддингов для всех изображений из валидационного набора.
2. Формирование RetrievalResults – структуры, содержащей результаты поиска.
3. Применение адаптивного порога (AdaptiveThresholding) для определения схожести.
4. Расчёт метрик:
   - EER и порога для верификации
   - MAP@K и CMC@K для ранжирования
5. Расчёт валидационной функции потерь

Валидация выполняется каждые `validate_every` эпох, а также после завершения обучения.

## Логирование

Система логирования включает несколько компонентов:

1. **Логи в консоль и файл**: Основная информация о процессе обучения.
2. **TensorBoard**: Визуализация метрик в реальном времени.
3. **CSV с результатами**: Таблица с метриками по эпохам.

Логируются следующие показатели:
- Функция потерь на обучении и валидации
- Метрики (EER, MAP@K, CMC@K)
- Скорость обучения (learning rate)
- Время выполнения эпох

## Управление чекпоинтами

Система создает следующие чекпоинты:

1. **Лучшая модель**: Сохраняется, когда целевая метрика (EER или loss) достигает лучшего значения.
2. **Финальная модель**: Сохраняется после завершения всех эпох обучения.

Чекпоинты включают:
- Веса модели (state_dict)
- Состояние оптимизатора
- Состояние планировщика
- Текущую эпоху и метрики
- Информацию о лучшем результате

Это позволяет при необходимости возобновить обучение с точки остановки.
